{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad45569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "\n",
    "import math\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import click as ck\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc, matthews_corrcoef\n",
    "from scipy.spatial import distance\n",
    "from scipy import sparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcb4509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_data_pkl': '/Users/robin/xbiome/datasets/protein/train_data.pkl',\n",
       " 'terms_pkl': '/Users/robin/xbiome/datasets/protein/terms.pkl',\n",
       " 'test_data_pkl': '/Users/robin/xbiome/datasets/protein/test_data.pkl',\n",
       " 'go_obo': '/Users/robin/xbiome/datasets/protein/go.obo',\n",
       " 'swissprot_pkl': '/Users/robin/xbiome/datasets/protein/swissprot.pkl',\n",
       " 'test_diamond_res': '/Users/robin/xbiome/datasets/protein/test_diamond.res',\n",
       " 'uniprot_sprot_dat': '/Users/robin/xbiome/datasets/protein/uniprot_sprot.dat.gz'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "base_path = r'/Users/robin/xbiome/datasets/protein'\n",
    "# 存储所有数据文件路径\n",
    "data_ls = os.walk(base_path).__next__()[2]\n",
    "data_path_dict = {}\n",
    "for data in data_ls:\n",
    "    file_name = data.split('.')[0] + '_' + data.split('.')[1]\n",
    "    data_path_dict[file_name] = os.path.join(base_path, data)\n",
    "\n",
    "# Minimum number of annotated proteins in each GO annotation\n",
    "min_count = 50\n",
    "\n",
    "# Maximum number of sequence\n",
    "MAXLEN = 2000\n",
    "\n",
    "# GO subontology (bp, mf, cc)\n",
    "onts = ['mf', 'bp', 'cc']\n",
    "\n",
    "data_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65186eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ontology(object):\n",
    "\n",
    "    def __init__(self, filename='data/go.obo', with_rels=False):\n",
    "        self.ont = self.load(filename, with_rels)\n",
    "        self.ic = None\n",
    "\n",
    "    def has_term(self, term_id):\n",
    "        return term_id in self.ont\n",
    "\n",
    "    def get_term(self, term_id):\n",
    "        if self.has_term(term_id):\n",
    "            return self.ont[term_id]\n",
    "        return None\n",
    "\n",
    "    def calculate_ic(self, annots):\n",
    "        cnt = Counter()\n",
    "        for x in annots:\n",
    "            cnt.update(x)\n",
    "        self.ic = {}\n",
    "        for go_id, n in cnt.items():\n",
    "            parents = self.get_parents(go_id)\n",
    "            if len(parents) == 0:\n",
    "                min_n = n\n",
    "            else:\n",
    "                min_n = min([cnt[x] for x in parents])\n",
    "\n",
    "            self.ic[go_id] = math.log(min_n / n, 2)\n",
    "    \n",
    "    def get_ic(self, go_id):\n",
    "        if self.ic is None:\n",
    "            raise Exception('Not yet calculated')\n",
    "        if go_id not in self.ic:\n",
    "            return 0.0\n",
    "        return self.ic[go_id]\n",
    "\n",
    "    def load(self, filename, with_rels):\n",
    "        ont = dict()\n",
    "        obj = None\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line == '[Term]':\n",
    "                    if obj is not None:\n",
    "                        ont[obj['id']] = obj\n",
    "                    obj = dict()\n",
    "                    obj['is_a'] = list()\n",
    "                    obj['part_of'] = list()\n",
    "                    obj['regulates'] = list()\n",
    "                    obj['alt_ids'] = list()\n",
    "                    obj['is_obsolete'] = False\n",
    "                    continue\n",
    "                elif line == '[Typedef]':\n",
    "                    if obj is not None:\n",
    "                        ont[obj['id']] = obj\n",
    "                    obj = None\n",
    "                else:\n",
    "                    if obj is None:\n",
    "                        continue\n",
    "                    l = line.split(\": \")\n",
    "                    if l[0] == 'id':\n",
    "                        obj['id'] = l[1]\n",
    "                    elif l[0] == 'alt_id':\n",
    "                        obj['alt_ids'].append(l[1])\n",
    "                    elif l[0] == 'namespace':\n",
    "                        obj['namespace'] = l[1]\n",
    "                    elif l[0] == 'is_a':\n",
    "                        obj['is_a'].append(l[1].split(' ! ')[0])\n",
    "                    elif with_rels and l[0] == 'relationship':\n",
    "                        it = l[1].split()\n",
    "                        # add all types of relationships\n",
    "                        obj['is_a'].append(it[1])\n",
    "                    elif l[0] == 'name':\n",
    "                        obj['name'] = l[1]\n",
    "                    elif l[0] == 'is_obsolete' and l[1] == 'true':\n",
    "                        obj['is_obsolete'] = True\n",
    "            if obj is not None:\n",
    "                ont[obj['id']] = obj\n",
    "        for term_id in list(ont.keys()):\n",
    "            for t_id in ont[term_id]['alt_ids']:\n",
    "                ont[t_id] = ont[term_id]\n",
    "            if ont[term_id]['is_obsolete']:\n",
    "                del ont[term_id]\n",
    "        for term_id, val in ont.items():\n",
    "            if 'children' not in val:\n",
    "                val['children'] = set()\n",
    "            for p_id in val['is_a']:\n",
    "                if p_id in ont:\n",
    "                    if 'children' not in ont[p_id]:\n",
    "                        ont[p_id]['children'] = set()\n",
    "                    ont[p_id]['children'].add(term_id)\n",
    "        return ont\n",
    "\n",
    "\n",
    "    def get_anchestors(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while(len(q) > 0):\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for parent_id in self.ont[t_id]['is_a']:\n",
    "                    if parent_id in self.ont:\n",
    "                        q.append(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_parents(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        for parent_id in self.ont[term_id]['is_a']:\n",
    "            if parent_id in self.ont:\n",
    "                term_set.add(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_namespace_terms(self, namespace):\n",
    "        terms = set()\n",
    "        for go_id, obj in self.ont.items():\n",
    "            if obj['namespace'] == namespace:\n",
    "                terms.add(go_id)\n",
    "        return terms\n",
    "\n",
    "    def get_namespace(self, term_id):\n",
    "        return self.ont[term_id]['namespace']\n",
    "    \n",
    "    def get_term_set(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while len(q) > 0:\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for ch_id in self.ont[t_id]['children']:\n",
    "                    q.append(ch_id)\n",
    "        return term_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd391c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIOLOGICAL_PROCESS = 'GO:0008150'\n",
    "MOLECULAR_FUNCTION = 'GO:0003674'\n",
    "CELLULAR_COMPONENT = 'GO:0005575'\n",
    "\n",
    "FUNC_DICT = {\n",
    "    'cc': CELLULAR_COMPONENT,\n",
    "    'mf': MOLECULAR_FUNCTION,\n",
    "    'bp': BIOLOGICAL_PROCESS}\n",
    "\n",
    "NAMESPACES = {\n",
    "    'cc': 'cellular_component',\n",
    "    'mf': 'molecular_function',\n",
    "    'bp': 'biological_process'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5553727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc(labels, preds):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve(labels.flatten(), preds.flatten())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc\n",
    "\n",
    "def compute_mcc(labels, preds):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    mcc = matthews_corrcoef(labels.flatten(), preds.flatten())\n",
    "    return mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f201dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_annotations(go, real_annots, pred_annots):\n",
    "    total = 0\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    p_total= 0\n",
    "    ru = 0.0\n",
    "    mi = 0.0\n",
    "    fps = []\n",
    "    fns = []\n",
    "    for i in range(len(real_annots)):\n",
    "        if len(real_annots[i]) == 0:\n",
    "            continue\n",
    "        tp = set(real_annots[i]).intersection(set(pred_annots[i]))\n",
    "        fp = pred_annots[i] - tp\n",
    "        fn = real_annots[i] - tp\n",
    "        for go_id in fp:\n",
    "            mi += go.get_ic(go_id)\n",
    "        for go_id in fn:\n",
    "            ru += go.get_ic(go_id)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        tpn = len(tp)\n",
    "        fpn = len(fp)\n",
    "        fnn = len(fn)\n",
    "        total += 1\n",
    "        recall = tpn / (1.0 * (tpn + fnn))\n",
    "        r += recall\n",
    "        if len(pred_annots[i]) > 0:\n",
    "            p_total += 1\n",
    "            precision = tpn / (1.0 * (tpn + fpn))\n",
    "            p += precision\n",
    "    ru /= total\n",
    "    mi /= total\n",
    "    r /= total\n",
    "    if p_total > 0:\n",
    "        p /= p_total\n",
    "    f = 0.0\n",
    "    if p + r > 0:\n",
    "        f = 2 * p * r / (p + r)\n",
    "    s = math.sqrt(ru * ru + mi * mi)\n",
    "    return f, p, r, s, ru, mi, fps, fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cfe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fmax():\n",
    "    fmax = 0.0\n",
    "    tmax = 0.0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    smin = 1000000.0\n",
    "    rus = []\n",
    "    mis = []\n",
    "    for t in range(1, 101): # the range in this loop has influence in the AUPR output\n",
    "        threshold = t / 100.0\n",
    "        preds = []\n",
    "        for i, row in enumerate(test_df.itertuples()):\n",
    "            annots = set()\n",
    "            for go_id, score in deep_preds[i].items():\n",
    "                if score >= threshold:\n",
    "                    annots.add(go_id)\n",
    "\n",
    "            new_annots = set()\n",
    "            for go_id in annots:\n",
    "                new_annots |= go_rels.get_anchestors(go_id)\n",
    "            preds.append(new_annots)\n",
    "            \n",
    "        # Filter classes\n",
    "        preds = list(map(lambda x: set(filter(lambda y: y in go_set, x)), preds))\n",
    "    \n",
    "        fscore, prec, rec, s, ru, mi, fps, fns = evaluate_annotations(go_rels, labels, preds)\n",
    "        avg_fp = sum(map(lambda x: len(x), fps)) / len(fps)\n",
    "        avg_ic = sum(map(lambda x: sum(map(lambda go_id: go_rels.get_ic(go_id), x)), fps)) / len(fps)\n",
    "        # print(f'{avg_fp} {avg_ic}')\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        # print(f'Fscore: {fscore}, Precision: {prec}, Recall: {rec} S: {s}, RU: {ru}, MI: {mi} threshold: {threshold}')\n",
    "        if fmax < fscore:\n",
    "            fmax = fscore\n",
    "            tmax = threshold\n",
    "        if smin > s:\n",
    "            smin = s\n",
    "    print(f'threshold: {tmax}')\n",
    "    print(f'Smin: {smin:0.3f}')\n",
    "    print(f'Fmax: {fmax:0.3f}')\n",
    "    precisions = np.array(precisions)\n",
    "    recalls = np.array(recalls)\n",
    "    sorted_index = np.argsort(recalls)\n",
    "    recalls = recalls[sorted_index]\n",
    "    precisions = precisions[sorted_index]\n",
    "    aupr = np.trapz(precisions, recalls)\n",
    "    print(f'AUPR: {aupr:0.3f}')\n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     plt.plot(recalls, precisions, color='darkorange',\n",
    "#              lw=lw, label=f'AUPR curve (area = {aupr:0.2f})')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('Recall')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.title('Area Under the Precision-Recall curve')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.savefig(f'results/aupr_{ont}_{alpha:0.2f}.pdf')\n",
    "#     df = pd.DataFrame({'precisions': precisions, 'recalls': recalls})\n",
    "#     df.to_pickle(f'results/PR_{ont}_{alpha:0.2f}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7d02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_rels = Ontology(data_path_dict['go_obo'], with_rels=True)\n",
    "terms_df = pd.read_pickle(data_path_dict['terms_pkl'])\n",
    "terms = terms_df['terms'].values.flatten()\n",
    "terms_dict = {v: i for i, v in enumerate(terms)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de1a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set: 3874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>proteins</th>\n",
       "      <th>accessions</th>\n",
       "      <th>sequences</th>\n",
       "      <th>annotations</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "      <th>exp_annotations</th>\n",
       "      <th>prop_annotations</th>\n",
       "      <th>cafa_target</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>6710</td>\n",
       "      <td>ACK1_YEAST</td>\n",
       "      <td>Q07622; D6VRF1;</td>\n",
       "      <td>MVNQGQPQPNLYDKHINMFPPARARESSHKLGNANSDRHGLPAQNI...</td>\n",
       "      <td>[GO:0005739|HDA, GO:0008047|IBA, GO:0031505|IM...</td>\n",
       "      <td>[IPR006597, IPR011990]</td>\n",
       "      <td>559292</td>\n",
       "      <td>[GO:0005739, GO:0031505, GO:0009967]</td>\n",
       "      <td>[GO:0043227, GO:0005737, GO:0110165, GO:003150...</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.74871105, 0.0049635754, 0.0017973002, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33330</th>\n",
       "      <td>210625</td>\n",
       "      <td>KIFC1_CRIGR</td>\n",
       "      <td>Q60443;</td>\n",
       "      <td>MKEALEPAKKRTRGLGAVTKIDTSRSKGPLLSSLSQPQGPTAAQKG...</td>\n",
       "      <td>[GO:0005769|IEA, GO:0005874|IEA, GO:0005815|IE...</td>\n",
       "      <td>[IPR019821, IPR001752, IPR036961, IPR027417]</td>\n",
       "      <td>10029</td>\n",
       "      <td>[GO:0030496]</td>\n",
       "      <td>[GO:0110165, GO:0005575, GO:0030496]</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.7487147, 0.0049634203, 0.0017972479, 0.0035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>109472</td>\n",
       "      <td>DSC3_HUMAN</td>\n",
       "      <td>Q14574; A6NN35; Q14200; Q9HAZ9;</td>\n",
       "      <td>MAAAGPRRSVRGAVCLHLLLTLVIFSRAGEACKKVILNVPSKLEAD...</td>\n",
       "      <td>[GO:0030054|IDA, GO:0005911|IBA, GO:0001533|TA...</td>\n",
       "      <td>[IPR002126, IPR015919, IPR020894, IPR000233, I...</td>\n",
       "      <td>9606</td>\n",
       "      <td>[GO:0030054, GO:0001533, GO:0016020, GO:000588...</td>\n",
       "      <td>[GO:0009913, GO:0140096, GO:0022610, GO:004358...</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0.74871624, 0.004963465, 0.0017972523, 0.0035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>687</td>\n",
       "      <td>2AAA_SCHPO</td>\n",
       "      <td>Q9UT08; Q10293;</td>\n",
       "      <td>MQTENQVNDLYPIAVLIDELKHDEITYRLNALERLSTIALALGPER...</td>\n",
       "      <td>[GO:0005737|IBA, GO:0005829|HDA, GO:0090443|ID...</td>\n",
       "      <td>[IPR011989, IPR016024, IPR000357, IPR021133]</td>\n",
       "      <td>284812</td>\n",
       "      <td>[GO:0005829, GO:0090443, GO:0110085, GO:004473...</td>\n",
       "      <td>[GO:0043227, GO:0022402, GO:0035556, GO:004578...</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.7487128, 0.004963536, 0.0017973394, 0.00351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>62522</td>\n",
       "      <td>CH1CO_SYNAS</td>\n",
       "      <td>Q2LQN9;</td>\n",
       "      <td>MKGPIKFNALSLQGRSVMSNQSNDTTITQRRDTMNELTEEQKLLME...</td>\n",
       "      <td>[GO:0003995|IEA, GO:0050660|IDA, GO:0052890|ID...</td>\n",
       "      <td>[IPR006089, IPR006091, IPR036250, IPR009075, I...</td>\n",
       "      <td>56780</td>\n",
       "      <td>[GO:0050660, GO:0052890, GO:0051262]</td>\n",
       "      <td>[GO:0043167, GO:1901363, GO:0051262, GO:005125...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.74871105, 0.0049635754, 0.0017973002, 0.003...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index     proteins                       accessions  \\\n",
       "1253     6710   ACK1_YEAST                  Q07622; D6VRF1;   \n",
       "33330  210625  KIFC1_CRIGR                          Q60443;   \n",
       "18394  109472   DSC3_HUMAN  Q14574; A6NN35; Q14200; Q9HAZ9;   \n",
       "95        687   2AAA_SCHPO                  Q9UT08; Q10293;   \n",
       "11368   62522  CH1CO_SYNAS                          Q2LQN9;   \n",
       "\n",
       "                                               sequences  \\\n",
       "1253   MVNQGQPQPNLYDKHINMFPPARARESSHKLGNANSDRHGLPAQNI...   \n",
       "33330  MKEALEPAKKRTRGLGAVTKIDTSRSKGPLLSSLSQPQGPTAAQKG...   \n",
       "18394  MAAAGPRRSVRGAVCLHLLLTLVIFSRAGEACKKVILNVPSKLEAD...   \n",
       "95     MQTENQVNDLYPIAVLIDELKHDEITYRLNALERLSTIALALGPER...   \n",
       "11368  MKGPIKFNALSLQGRSVMSNQSNDTTITQRRDTMNELTEEQKLLME...   \n",
       "\n",
       "                                             annotations  \\\n",
       "1253   [GO:0005739|HDA, GO:0008047|IBA, GO:0031505|IM...   \n",
       "33330  [GO:0005769|IEA, GO:0005874|IEA, GO:0005815|IE...   \n",
       "18394  [GO:0030054|IDA, GO:0005911|IBA, GO:0001533|TA...   \n",
       "95     [GO:0005737|IBA, GO:0005829|HDA, GO:0090443|ID...   \n",
       "11368  [GO:0003995|IEA, GO:0050660|IDA, GO:0052890|ID...   \n",
       "\n",
       "                                               interpros    orgs  \\\n",
       "1253                              [IPR006597, IPR011990]  559292   \n",
       "33330       [IPR019821, IPR001752, IPR036961, IPR027417]   10029   \n",
       "18394  [IPR002126, IPR015919, IPR020894, IPR000233, I...    9606   \n",
       "95          [IPR011989, IPR016024, IPR000357, IPR021133]  284812   \n",
       "11368  [IPR006089, IPR006091, IPR036250, IPR009075, I...   56780   \n",
       "\n",
       "                                         exp_annotations  \\\n",
       "1253                [GO:0005739, GO:0031505, GO:0009967]   \n",
       "33330                                       [GO:0030496]   \n",
       "18394  [GO:0030054, GO:0001533, GO:0016020, GO:000588...   \n",
       "95     [GO:0005829, GO:0090443, GO:0110085, GO:004473...   \n",
       "11368               [GO:0050660, GO:0052890, GO:0051262]   \n",
       "\n",
       "                                        prop_annotations  cafa_target  \\\n",
       "1253   [GO:0043227, GO:0005737, GO:0110165, GO:003150...         True   \n",
       "33330               [GO:0110165, GO:0005575, GO:0030496]        False   \n",
       "18394  [GO:0009913, GO:0140096, GO:0022610, GO:004358...         True   \n",
       "95     [GO:0043227, GO:0022402, GO:0035556, GO:004578...         True   \n",
       "11368  [GO:0043167, GO:1901363, GO:0051262, GO:005125...        False   \n",
       "\n",
       "                                                  labels  \\\n",
       "1253   [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "33330  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18394  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, ...   \n",
       "95     [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11368  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                   preds  \n",
       "1253   [0.74871105, 0.0049635754, 0.0017973002, 0.003...  \n",
       "33330  [0.7487147, 0.0049634203, 0.0017972479, 0.0035...  \n",
       "18394  [0.74871624, 0.004963465, 0.0017972523, 0.0035...  \n",
       "95     [0.7487128, 0.004963536, 0.0017973394, 0.00351...  \n",
       "11368  [0.74871105, 0.0049635754, 0.0017973002, 0.003...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "train_df = pd.read_pickle(data_path_dict['train_data_pkl'])\n",
    "test_df = pd.read_pickle(data_path_dict['test_data_pkl'])\n",
    "\n",
    "predict_results = '/Users/robin/xbiome/DeepFold/tools/work_dir/predictions.pkl'\n",
    "with open(predict_results, 'rb') as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions\n",
    "test_df['labels'] = list(labels)\n",
    "test_df['preds'] = list(preds)\n",
    "\n",
    "print(\"Length of test set: \" + str(len(test_df)))\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc9d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = train_df['prop_annotations'].values\n",
    "annotations = list(map(lambda x: set(x), annotations))\n",
    "test_annotations = test_df['prop_annotations'].values\n",
    "test_annotations = list(map(lambda x: set(x), test_annotations))\n",
    "go_rels.calculate_ic(annotations + test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4cb7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ics = {}\n",
    "for term in terms:\n",
    "    ics[term] = go_rels.get_ic(term)\n",
    "\n",
    "prot_index = {}\n",
    "for i, row in enumerate(train_df.itertuples()):\n",
    "    prot_index[row.proteins] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48291427",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_scores = {}\n",
    "with open(data_path_dict['test_diamond_res']) as f:\n",
    "    for line in f:\n",
    "        it = line.strip().split()\n",
    "        if it[0] not in diamond_scores:\n",
    "            diamond_scores[it[0]] = {}\n",
    "        diamond_scores[it[0]][it[1]] = float(it[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0e41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_preds = []\n",
    "#print('Diamond preds')\n",
    "for i, row in enumerate(test_df.itertuples()):\n",
    "    annots = {}\n",
    "    prot_id = row.proteins\n",
    "    # BlastKNN\n",
    "    if prot_id in diamond_scores:\n",
    "        sim_prots = diamond_scores[prot_id]\n",
    "        allgos = set()\n",
    "        total_score = 0.0\n",
    "        for p_id, score in sim_prots.items():\n",
    "            allgos |= annotations[prot_index[p_id]]\n",
    "            total_score += score\n",
    "        allgos = list(sorted(allgos))\n",
    "        sim = np.zeros(len(allgos), dtype=np.float32)\n",
    "        for j, go_id in enumerate(allgos):\n",
    "            s = 0.0\n",
    "            for p_id, score in sim_prots.items():\n",
    "                if go_id in annotations[prot_index[p_id]]:\n",
    "                    s += score\n",
    "            sim[j] = s / total_score\n",
    "        ind = np.argsort(-sim)\n",
    "        for go_id, score in zip(allgos, sim):\n",
    "            annots[go_id] = score\n",
    "    blast_preds.append(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee80ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf\n",
      "threshold: 0.1\n",
      "Smin: 15.120\n",
      "Fmax: 0.318\n",
      "AUPR: 0.196\n",
      "bp\n",
      "threshold: 0.14\n",
      "Smin: 53.135\n",
      "Fmax: 0.320\n",
      "AUPR: 0.230\n",
      "cc\n",
      "threshold: 0.22\n",
      "Smin: 13.138\n",
      "Fmax: 0.601\n",
      "AUPR: 0.533\n"
     ]
    }
   ],
   "source": [
    "# DeepGOPlus\n",
    "for ont in onts:\n",
    "    print(ont)\n",
    "    go_set = go_rels.get_namespace_terms(NAMESPACES[ont])\n",
    "    go_set.remove(FUNC_DICT[ont])\n",
    "    labels = test_df['prop_annotations'].values\n",
    "    labels = list(map(lambda x: set(filter(lambda y: y in go_set, x)), labels))\n",
    "    # print(len(go_set))\n",
    "    deep_preds = []\n",
    "    # alphas = {NAMESPACES['mf']: 0.55, NAMESPACES['bp']: 0.59, NAMESPACES['cc']: 0.46}\n",
    "    alphas = {NAMESPACES['mf']: 0, NAMESPACES['bp']: 0, NAMESPACES['cc']: 0}\n",
    "    # alphas = {NAMESPACES['mf']: 1, NAMESPACES['bp']: 1, NAMESPACES['cc']: 1}\n",
    "\n",
    "    for i, row in enumerate(test_df.itertuples()):\n",
    "        annots_dict = blast_preds[i].copy()\n",
    "        for go_id in annots_dict:\n",
    "            annots_dict[go_id] *= alphas[go_rels.get_namespace(go_id)]\n",
    "        for j, score in enumerate(row.preds):\n",
    "            go_id = terms[j]\n",
    "            score *= 1 - alphas[go_rels.get_namespace(go_id)]\n",
    "            if go_id in annots_dict:\n",
    "                annots_dict[go_id] += score\n",
    "            else:\n",
    "                annots_dict[go_id] = score\n",
    "        deep_preds.append(annots_dict)\n",
    "\n",
    "    compute_fmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be55fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('AUTHOR DeepGOPlus')\\nprint('MODEL 1')\\nprint('KEYWORDS sequence alignment.')\\nfor i, row in enumerate(test_df.itertuples()):\\n    prot_id = row.proteins\\n    for go_id, score in deep_preds[i].items():\\n        print(f'{prot_id}\\t{go_id}\\t{score:.2f}')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print('AUTHOR DeepGOPlus')\n",
    "print('MODEL 1')\n",
    "print('KEYWORDS sequence alignment.')\n",
    "for i, row in enumerate(test_df.itertuples()):\n",
    "    prot_id = row.proteins\n",
    "    for go_id, score in deep_preds[i].items():\n",
    "        print(f'{prot_id}\\t{go_id}\\t{score:.2f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efeec24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
