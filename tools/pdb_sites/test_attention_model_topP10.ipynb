{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test p2go partial component mfo best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepfold.utils.make_graph import build_graph\n",
    "from deepfold.utils.model import load_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from deepfold.models.esm_model import MLPLayer,MLPLayer3D\n",
    "from deepfold.models.gnn_model import GCN\n",
    "\n",
    "\n",
    "\n",
    "# attention  module\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项 Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作.\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力.\"\"\"\n",
    "    def __init__(self, dropout, lambd=1,**kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.lambd = lambd\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(self.lambd * d)\n",
    "        # scores /= self.tao\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values),self.attention_weights\n",
    "\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状.\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作.\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力.\"\"\"\n",
    "    def __init__(self,\n",
    "                 key_size,\n",
    "                 query_size,\n",
    "                 value_size,\n",
    "                 num_hiddens,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 bias=False,\n",
    "                 lambd=None,\n",
    "                 **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout,lambd=lambd)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None, output_attentions=True):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(valid_lens,\n",
    "                                                 repeats=self.num_heads,\n",
    "                                                 dim=0)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output,weight = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        weight_concat = transpose_output(weight, self.num_heads)\n",
    "        outputs = (output_concat, weight_concat) if output_attentions else (output_concat,)\n",
    "        return outputs\n",
    "\n",
    "class LabelBasedAttention(nn.Module):\n",
    "    def __init__(self, label_dim, word_dim, latent_dim, nb_labels, nb_words,components_factor=2,temperature=2):\n",
    "        super().__init__()\n",
    "        self.label_dim = label_dim\n",
    "        self.word_dim = word_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc_label = MLPLayer(self.label_dim, self.latent_dim)\n",
    "        self.fc_word = MLPLayer3D(self.word_dim, self.latent_dim)\n",
    "        self.nb_labels = nb_labels\n",
    "        self.nb_words = nb_words\n",
    "        assert components_factor > 0\n",
    "        self.nb_components = int(self.nb_labels/(components_factor*(1+int(self.nb_labels/self.nb_words))))\n",
    "        self.component_embedding = nn.Parameter(torch.randn((self.nb_components,self.latent_dim)),requires_grad=True)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, label_embedding, word_embedding, lengths):\n",
    "        word_embedding = self.fc_word(word_embedding)\n",
    "        label_embedding = self.fc_label(label_embedding)\n",
    "        word_embedding = word_embedding.transpose(-1,-2)\n",
    "        component_embedding = self.component_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        c_w = torch.bmm(component_embedding,word_embedding)\n",
    "        label_embedding = label_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        l_c = torch.bmm(label_embedding,component_embedding.transpose(-1,-2))\n",
    "        l_c = l_c.softmax(dim=-1)\n",
    "        l_w = torch.bmm(l_c,c_w)\n",
    "        l_w /= self.temperature\n",
    "        l_w = masked_softmax(l_w, lengths+1)\n",
    "        label_level_embedding = torch.bmm(l_w,word_embedding.transpose(-1,-2))\n",
    "        \n",
    "        return label_level_embedding, l_w\n",
    "\n",
    "class P2GO(nn.Module):\n",
    "    def __init__(self,\n",
    "                 terms_embedding,adj,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 aa_dim=1280,\n",
    "                 latent_dim=256,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.terms_embedding = nn.Parameter(terms_embedding,requires_grad=True)\n",
    "        self.terms_dim = terms_embedding.shape[1]\n",
    "        self.latent_dim = latent_dim\n",
    "        self.adj = adj\n",
    "        \n",
    "        # backbone\n",
    "        backbone, _ = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        unfreeze_layers = None # [32] # total 0-32 layer\n",
    "        self.backbone = self.unfreeze(backbone,unfreeze_layers)\n",
    "        self.nb_classes = adj.shape[0]\n",
    "        # label based attention\n",
    "        self.label_attention = LabelBasedAttention(label_dim=self.terms_dim,word_dim=aa_dim,latent_dim=latent_dim,nb_labels=self.nb_classes,nb_words=1024,\n",
    "                                                    components_factor=4,temperature=2)\n",
    "        # go transform\n",
    "        self.go_transfrom = MLPLayer(self.terms_dim,self.latent_dim)\n",
    "        # gnn module\n",
    "        self.gcn = GCN(latent_dim, latent_dim)\n",
    "        # output layer\n",
    "        self.go_transform_post = MLPLayer(int(2 * latent_dim), latent_dim)\n",
    "        # post mlp\n",
    "        self.post_mlp = MLPLayer(self.nb_classes, self.nb_classes)\n",
    "\n",
    "    def unfreeze(self, backbone, unfreeze_layers:list):\n",
    "        for name ,param in backbone.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        if unfreeze_layers is not None:\n",
    "            if 'lm_head' in name:\n",
    "                param.requires_grad = True\n",
    "            for idx in unfreeze_layers:\n",
    "                for _, p in backbone.layers[idx].named_parameters():\n",
    "                    p.requires_grad = True\n",
    "        return backbone\n",
    "\n",
    "    def forward(self, input_ids, lengths, labels, output_attention_weights=True):\n",
    "        # backbone\n",
    "        x = self.backbone(input_ids, repr_layers=[33])['representations'][33]\n",
    "        # x = x[:, 1:]\n",
    "        # x [B,L,C]\n",
    "        label_level_embedding, weights = self.label_attention(self.terms_embedding, x, lengths)\n",
    "        go_embedding = self.go_transfrom(self.terms_embedding)\n",
    "        # go embedding\n",
    "        go_out = self.gcn(go_embedding, self.adj)\n",
    "        # output layer\n",
    "        go_out = torch.cat((go_embedding, go_out), dim=1)\n",
    "        go_out = self.go_transform_post(go_out)\n",
    "        go_out = go_out.repeat((x.shape[0], 1, 1))\n",
    "        logits = self.post_mlp(torch.sum(go_out * label_level_embedding, dim=-1))\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(logits.view(-1, self.nb_classes),\n",
    "                            labels.view(-1, self.nb_classes))\n",
    "            outputs = (logits,loss)\n",
    "        if output_attention_weights:\n",
    "            outputs = (loss, logits, weights)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "        self.data_path='esm'\n",
    "        self.data_path='/share/home/niejianzheng/xbiome/datasets/protein/cafa3/'\n",
    "        self.resume = '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_mfo__new_adj_top2down_t2f4/checkpoint_4.pth'\n",
    "        self.batch_size = 4\n",
    "        self.workers=1\n",
    "        self.namespace = 'mfo'\n",
    "        self.temperature=2,\n",
    "        self.components_factor=4\n",
    "\n",
    "# Dataset and DataLoader\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>res</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12as</td>\n",
       "      <td>[46, 100, 116, 235, 248, 251]</td>\n",
       "      <td>MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13pk</td>\n",
       "      <td>[39, 219, 376, 399]</td>\n",
       "      <td>EKKSINECDLKGKKVLIRVDFNVPVKNGKITNDYRIRSALPTLKKV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a05</td>\n",
       "      <td>[140, 190, 222, 246, 250]</td>\n",
       "      <td>MKKIAIFAGDGIGPEIVAAARQVLDAVDQAAHLGLRCTEGLVGGAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a0i</td>\n",
       "      <td>[34, 238, 240]</td>\n",
       "      <td>VNIKTNPFKAVSFVESAIKKALDNAGYLIAEIKYDGVRGNICVDNT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a16</td>\n",
       "      <td>[38, 243, 260, 271, 350, 354, 361, 383, 387, 4...</td>\n",
       "      <td>SEISRQEFQRRRQALVEQMQPGSAALIFAAPEVTRSADSEYPYRQN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>7enl</td>\n",
       "      <td>[39, 159, 168, 211, 246, 295, 320, 345, 373, 396]</td>\n",
       "      <td>AVSKVYARSVYDSRGNPTVEVELTTEKGVFRSIVPSGASTGVHEAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>7nn9</td>\n",
       "      <td>[151, 220, 277, 371, 412]</td>\n",
       "      <td>RDFNNLTKGLCTINSWHIYGKDNAVRIGEDSDVLVTREPYVSCDPD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>7odc</td>\n",
       "      <td>[69, 197, 274]</td>\n",
       "      <td>MSSFTKDEFDCHILDEGFTAKDILDQKINEVSSSDDKDAFYVADLG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>8pch</td>\n",
       "      <td>[19, 25, 159]</td>\n",
       "      <td>YPPSMDWRKKGNFVSPVKNQGSCGSCWTFSTTGALESAVAIATGKM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>9pap</td>\n",
       "      <td>[19, 25, 159, 175]</td>\n",
       "      <td>IPEYVDWRQKGAVTPVKNQGSCGSCWAFSAVVTIEGIIKIRTGNLN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pdb_id                                                res  \\\n",
       "0     12as                      [46, 100, 116, 235, 248, 251]   \n",
       "1     13pk                                [39, 219, 376, 399]   \n",
       "2     1a05                          [140, 190, 222, 246, 250]   \n",
       "3     1a0i                                     [34, 238, 240]   \n",
       "4     1a16  [38, 243, 260, 271, 350, 354, 361, 383, 387, 4...   \n",
       "..     ...                                                ...   \n",
       "946   7enl  [39, 159, 168, 211, 246, 295, 320, 345, 373, 396]   \n",
       "947   7nn9                          [151, 220, 277, 371, 412]   \n",
       "948   7odc                                     [69, 197, 274]   \n",
       "949   8pch                                      [19, 25, 159]   \n",
       "950   9pap                                 [19, 25, 159, 175]   \n",
       "\n",
       "                                              sequence  \n",
       "0    MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQD...  \n",
       "1    EKKSINECDLKGKKVLIRVDFNVPVKNGKITNDYRIRSALPTLKKV...  \n",
       "2    MKKIAIFAGDGIGPEIVAAARQVLDAVDQAAHLGLRCTEGLVGGAA...  \n",
       "3    VNIKTNPFKAVSFVESAIKKALDNAGYLIAEIKYDGVRGNICVDNT...  \n",
       "4    SEISRQEFQRRRQALVEQMQPGSAALIFAAPEVTRSADSEYPYRQN...  \n",
       "..                                                 ...  \n",
       "946  AVSKVYARSVYDSRGNPTVEVELTTEKGVFRSIVPSGASTGVHEAL...  \n",
       "947  RDFNNLTKGLCTINSWHIYGKDNAVRIGEDSDVLVTREPYVSCDPD...  \n",
       "948  MSSFTKDEFDCHILDEGFTAKDILDQKINEVSSSDDKDAFYVADLG...  \n",
       "949  YPPSMDWRKKGNFVSPVKNQGSCGSCWTFSTTGALESAVAIATGKM...  \n",
       "950  IPEYVDWRQKGAVTPVKNQGSCGSCWAFSAVVTIEGIIKIRTGNLN...  \n",
       "\n",
       "[951 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle('test_res.pkl')\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from typing import Dict\n",
    "import esm\n",
    "import gc\n",
    "import random\n",
    "\n",
    "class TestAttentionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 test_file_name,\n",
    "                 label_map,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 max_length: int = 1024,\n",
    "                 truncate: bool = True,\n",
    "                 random_crop: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seqs, self.res = self.load_dataset(test_file_name)\n",
    "        self.terms_dict = label_map\n",
    "        self.num_classes = len(self.terms_dict)\n",
    "        self.max_length = max_length\n",
    "        self.truncate = truncate\n",
    "        self.random_crop = random_crop\n",
    "\n",
    "        esm_model, self.alphabet = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.free_memory(esm_model)\n",
    "    \n",
    "    def free_memory(self, esm_model):\n",
    "        del esm_model\n",
    "        gc.collect()\n",
    "        print('Delete the esm model, free memory!')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.seqs[idx]\n",
    "        if self.truncate:\n",
    "            sequence = sequence[:self.max_length - 2]\n",
    "        length = len(sequence)\n",
    "        multilabel = [0] * self.num_classes\n",
    "        return sequence, length, multilabel,self.res[idx]\n",
    "\n",
    "    def load_dataset(self, test_df_file):\n",
    "        df = pd.read_pickle(test_df_file)\n",
    "        seq = list(df['sequence'])\n",
    "        res = list(df['res'])\n",
    "        return seq,res\n",
    "\n",
    "    def collate_fn(self, examples) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Function to transform tokens string to IDs; it depends on the model\n",
    "        used.\"\"\"\n",
    "        sequences_list = [ex[0] for ex in examples]\n",
    "        lengths = [ex[1] for ex in examples]\n",
    "        multilabel_list = [ex[2] for ex in examples]\n",
    "        res_list = [ex[3] for ex in examples]\n",
    "\n",
    "        labels, strs, all_tokens = self.batch_converter([\n",
    "            ('', sequence) for sequence in sequences_list\n",
    "        ])\n",
    "\n",
    "        # The model is trained on truncated sequences and passing longer ones in at\n",
    "        # infernce will cause an error. See https://github.com/facebookresearch/esm/issues/21\n",
    "        if self.truncate:\n",
    "            all_tokens = all_tokens[:, :self.max_length]\n",
    "\n",
    "        if all_tokens.shape[1] < 1024:\n",
    "            tmp = torch.ones((all_tokens.shape[0], 1024 - all_tokens.shape[1]))\n",
    "            all_tokens = torch.cat([all_tokens, tmp], dim=1)\n",
    "        all_tokens = all_tokens.int()\n",
    "        all_tokens = all_tokens.to('cpu')\n",
    "        encoded_inputs = {\n",
    "            'input_ids': all_tokens,\n",
    "        }\n",
    "        encoded_inputs['lengths'] = torch.tensor(lengths, dtype=torch.int)\n",
    "        encoded_inputs['labels'] = torch.tensor(multilabel_list,\n",
    "                                                dtype=torch.int)\n",
    "        encoded_inputs['res'] = res_list\n",
    "        return encoded_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated terms: 6367\n",
      "number of edges:7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete the esm model, free memory!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "args.gpu = 0\n",
    "# Dataset and DataLoader\n",
    "adj, multi_hot_vector, label_map, label_map_ivs,_ = build_graph(\n",
    "    data_path=args.data_path, namespace=args.namespace)\n",
    "test_dataset = TestAttentionDataset(test_file_name='test_res.pkl',label_map=label_map)\n",
    "# dataloders\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=args.workers,\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 0, 20, 15,  ...,  1,  1,  1],\n",
       "         [ 0,  9, 15,  ...,  1,  1,  1],\n",
       "         [ 0, 20, 15,  ...,  1,  1,  1],\n",
       "         [ 0,  7, 17,  ...,  1,  1,  1]], dtype=torch.int32),\n",
       " 'lengths': tensor([330, 415, 358, 348], dtype=torch.int32),\n",
       " 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32),\n",
       " 'res': [[46, 100, 116, 235, 248, 251],\n",
       "  [39, 219, 376, 399],\n",
       "  [140, 190, 222, 246, 250],\n",
       "  [34, 238, 240]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0][46].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R', 'R')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dataset.alphabet.get_tok(input_ids[0][100].item()),test_df.sequence[0][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_mfo__new_adj_top2down_t2f4/checkpoint_4.pth'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# model\n",
    "terms_all = pd.read_pickle(os.path.join(args.data_path,'all_terms_partial_order_embeddings.pkl'))\n",
    "terms = pd.read_pickle(os.path.join(args.data_path,args.namespace,args.namespace + '_terms.pkl'))\n",
    "terms_embedding = terms.merge(terms_all)\n",
    "embeddings = np.concatenate([np.array(embedding,ndmin=2) for embedding in terms_embedding.embeddings.values])\n",
    "terms_embedding = torch.Tensor(embeddings)\n",
    "terms_embedding = terms_embedding.cuda()\n",
    "adj = adj.cuda()\n",
    "model = P2GO(terms_embedding, adj, model_dir= 'esm1b_t33_650M_UR50S', aa_dim= 1280, latent_dim = 256, dropout_rate=0.1)\n",
    "if args.resume is not None:\n",
    "    model_state, optimizer_state = load_model_checkpoint(args.resume)\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "batch = {key: val.cuda() for key, val in batch.items() if type(val) is torch.Tensor}\n",
    "(loss, logits, weights) = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043, device='cuda:0',\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits.sigmoid().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0182e-05, 1.0657e-05, 2.9552e-05,  ..., 8.0472e-06, 3.0107e-05,\n",
       "         3.5217e-05],\n",
       "        [1.6076e-05, 8.4371e-06, 2.8903e-05,  ..., 1.4782e-05, 8.8768e-05,\n",
       "         4.2436e-05],\n",
       "        [1.4485e-05, 9.1310e-06, 3.5951e-05,  ..., 9.7281e-06, 1.1790e-04,\n",
       "         8.1055e-05],\n",
       "        [1.6528e-05, 2.4249e-05, 9.5311e-06,  ..., 1.0609e-05, 3.5822e-05,\n",
       "         1.9297e-05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 21,  6,  8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(logits > 0.4,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = logits[0].sort(descending=True).indices[logits[0].sort(descending=True).values>0.40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0003674\n",
      "GO:0003824\n",
      "GO:0016874\n",
      "GO:0005488\n"
     ]
    }
   ],
   "source": [
    "for idx in idxs:\n",
    "    print(label_map_ivs[idx.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.2074e-05, 7.1975e-05, 1.4078e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0][idxs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.1193, 0.0694, 0.0579,  ..., 0.0000, 0.0000, 0.0000]),\n",
       "indices=tensor([181, 183, 220,  ..., 565, 566, 567]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0][idxs[3]].sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = batch['lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(330, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030303030303030303"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.5551, 0.2011, 0.1488,  ..., 0.0000, 0.0000, 0.0000]),\n",
       "indices=tensor([116, 110, 102,  ..., 565, 566, 567]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_weights = weights[0][idxs[0]].sort(descending=True)\n",
    "sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([116, 110, 102, 213, 252, 214, 108, 215, 105, 220, 212, 265, 299,  74,\n",
       "         46, 264, 292,  71, 211, 255, 181, 206, 210, 216, 247, 217, 207, 104,\n",
       "        251,  78,   9, 106, 103, 112])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_weights.indices[:int(0.1*(length[0])+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0003674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([116, 110, 102, 213, 252])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [46, 100, 116, 235, 248, 251]\t\n",
    "print(label_map_ivs[idxs[0].item()])\n",
    "weights[0][idxs[0]].sort(descending=True)[].indices[weights[0][idxs[0]].sort(descending=True).values > 0.012]\n",
    "\n",
    "# [115, 109, 101, 212, 251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0003824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([299,  53,  50, 214, 264, 293,  49, 269])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [46, 100, 116, 235, 248, 251]\t\n",
    "print(label_map_ivs[idxs[1].item()])\n",
    "weights[0][idxs[1]].sort(descending=True).indices[weights[0][idxs[1]].sort(descending=True).values > 0.012]\n",
    "\n",
    "# [298,  52,  49, 213, 263, 292,  48, 268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [46, 100, 116, 235, 248, 251]\t\n",
    "set(list(weights[0][idxs[3]].sort(descending=True).indices[weights[0][idxs[3]].sort(descending=True).values > 0.012].sort().values-1)).intersection(set(test_df.res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0016874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([185,  53, 299, 284,  39, 298,  52])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [46, 100, 116, 235, 248, 251]\t\n",
    "print(label_map_ivs[idxs[2].item()])\n",
    "weights[0][idxs[2]].sort(descending=True).indices[weights[0][idxs[2]].sort(descending=True).values > 0.012]\n",
    "\n",
    "# [184,  52, 298, 283,  38, 297,  51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([181, 183, 220, 195, 180, 200, 111, 209, 102, 203,  39, 170, 152, 251,\n",
       "        107, 208, 186, 178, 202, 194, 187, 148, 182])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [46, 100, 116, 235, 248, 251]\n",
    "print(label_map_ivs[idxs[3].item()])\t\n",
    "weights[0][idxs[3]].sort(descending=True).indices[weights[0][idxs[3]].sort(descending=True).values > 0.012]\n",
    "\n",
    "# [180, 182, 219, 194, 179, 199, 110, 208, 101, 202,  38, 169, 151, 250,\n",
    "#         106, 207, 185, 177, 201, 193, 186, 147, 181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(weights[0][idxs[1]].sort(descending=True).indices[weights[0][idxs[3]].sort(descending=True).values > 0.012].sort().values-1)).intersection(set(test_df.res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018049491175613497\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "score_total = []\n",
    "for i,batch in enumerate(test_loader):\n",
    "    lengths = batch['lengths']\n",
    "    ress = batch['res']\n",
    "    batch = {key: val.cuda() for key, val in batch.items() if type(val) is torch.Tensor}\n",
    "    (_, logits, weights) = model(**batch)\n",
    "    preds = logits.sigmoid().detach().cpu()\n",
    "    weights = weights.detach().cpu()\n",
    "    for pred,weight,length,res in zip(preds,weights,lengths,ress):\n",
    "        idxs = pred.sort(descending=True).indices[pred.sort(descending=True).values>0.40]\n",
    "        \n",
    "        pred_sites =[]\n",
    "        for idx in idxs:\n",
    "            sorted_weight = weight[idx].sort(descending=True)\n",
    "            candidate = sorted_weight.indices[:int(0.1*length+1)]-1\n",
    "            candidate = list(candidate.detach().cpu().numpy())\n",
    "            pred_sites.extend(candidate)\n",
    "        score = len(set(list(pred_sites)).intersection(set(res)))/len(set(list(pred_sites)).union(set(res)))\n",
    "        score_total.append(score)\n",
    "print(sum(score_total)/len(score_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test p2go partial component postmlp fv bpo t4f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from deepfold.models.esm_model import MLPLayer,MLPLayer3D\n",
    "from deepfold.models.gnn_model import GCN\n",
    "\n",
    "# attention  module\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项 Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作.\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "class LabelBasedAttention(nn.Module):\n",
    "    def __init__(self, label_dim, word_dim, latent_dim, nb_labels, nb_words,components_factor=2,temperature=2):\n",
    "        super().__init__()\n",
    "        self.label_dim = label_dim\n",
    "        self.word_dim = word_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc_q = MLPLayer(self.label_dim, self.latent_dim)\n",
    "        self.fc_k = MLPLayer3D(self.word_dim, self.latent_dim)\n",
    "        self.nb_labels = nb_labels\n",
    "        self.nb_words = nb_words\n",
    "        assert components_factor > 0\n",
    "        self.nb_components = int(self.nb_labels/(components_factor*(1+int(self.nb_labels/self.nb_words))))\n",
    "        self.component_embedding = nn.Parameter(torch.randn((self.nb_components,self.latent_dim)),requires_grad=True)\n",
    "        self.temperature = temperature\n",
    "        # fc_v\n",
    "        self.fc_v = MLPLayer3D(self.word_dim, self.latent_dim)\n",
    "\n",
    "    def forward(self, label_embedding, word_embedding, lengths):\n",
    "        k_embedding = self.fc_k(word_embedding)\n",
    "        q_embedding = self.fc_q(label_embedding)\n",
    "        k_embedding = k_embedding.transpose(-1,-2)\n",
    "        component_embedding = self.component_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        c_w = torch.bmm(component_embedding,k_embedding)\n",
    "        q_embedding = q_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        l_c = torch.bmm(q_embedding,component_embedding.transpose(-1,-2))\n",
    "        l_c = l_c.softmax(dim=-1)\n",
    "        l_w = torch.bmm(l_c,c_w)\n",
    "        l_w /= self.temperature\n",
    "        l_w = masked_softmax(l_w, lengths+1)\n",
    "        label_level_embedding = torch.bmm(l_w,self.fc_v(word_embedding))\n",
    "        \n",
    "        return label_level_embedding, l_w\n",
    "\n",
    "class P2GO(nn.Module):\n",
    "    def __init__(self,\n",
    "                 terms_embedding,adj,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 aa_dim=1280,\n",
    "                 latent_dim=256,\n",
    "                 dropout_rate=0.1,temperature=2,components_factor=2):\n",
    "        super().__init__()\n",
    "        self.terms_embedding = nn.Parameter(terms_embedding,requires_grad=True)\n",
    "        self.terms_dim = terms_embedding.shape[1]\n",
    "        self.latent_dim = latent_dim\n",
    "        self.adj = adj\n",
    "        \n",
    "        # backbone\n",
    "        backbone, _ = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        unfreeze_layers = None # [32] # total 0-32 layer\n",
    "        self.backbone = self.unfreeze(backbone,unfreeze_layers)\n",
    "        self.nb_classes = adj.shape[0]\n",
    "        # label based attention\n",
    "        self.label_attention = LabelBasedAttention(label_dim=self.terms_dim,\n",
    "                                                word_dim=aa_dim,latent_dim=latent_dim,\n",
    "                                                nb_labels=self.nb_classes,nb_words=1024,\n",
    "                                                components_factor=components_factor,\n",
    "                                                temperature=temperature)\n",
    "        # go transform\n",
    "        self.go_transfrom = MLPLayer(self.terms_dim,self.latent_dim,dropout_rate)\n",
    "        # gnn module\n",
    "        self.gcn = GCN(latent_dim, latent_dim)\n",
    "        # output layer\n",
    "        self.go_transform_post = MLPLayer(int(2 * latent_dim), latent_dim, dropout_rate)\n",
    "        # post mlp\n",
    "        self.post_mlp = MLPLayer(self.nb_classes, self.nb_classes, dropout_rate)\n",
    "\n",
    "    def unfreeze(self, backbone, unfreeze_layers:list):\n",
    "        for name ,param in backbone.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        if unfreeze_layers is not None:\n",
    "            if 'lm_head' in name:\n",
    "                param.requires_grad = True\n",
    "            for idx in unfreeze_layers:\n",
    "                for _, p in backbone.layers[idx].named_parameters():\n",
    "                    p.requires_grad = True\n",
    "        return backbone\n",
    "\n",
    "    def forward(self, input_ids, lengths, labels, output_attention_weights=True):\n",
    "        # backbone\n",
    "        x = self.backbone(input_ids, repr_layers=[33])['representations'][33]\n",
    "        # x = x[:, 1:]\n",
    "        # x [B,L,C]\n",
    "        label_level_embedding, weights = self.label_attention(self.terms_embedding, x, lengths)\n",
    "        go_embedding = self.go_transfrom(self.terms_embedding)\n",
    "        # go embedding\n",
    "        go_out = self.gcn(go_embedding, self.adj)\n",
    "        # output layer\n",
    "        go_out = torch.cat((go_embedding, go_out), dim=1)\n",
    "        go_out = self.go_transform_post(go_out)\n",
    "        go_out = go_out.repeat((x.shape[0], 1, 1))\n",
    "        logits = self.post_mlp(torch.sum(go_out * label_level_embedding, dim=-1))\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(logits.view(-1, self.nb_classes),\n",
    "                            labels.view(-1, self.nb_classes))\n",
    "            outputs = (logits,loss)\n",
    "        if output_attention_weights:\n",
    "            if labels is not None:\n",
    "                outputs = (loss, logits, weights)\n",
    "            else:\n",
    "                outputs = (logits, weights)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "        self.data_path='esm'\n",
    "        self.data_path='/share/home/niejianzheng/xbiome/datasets/protein/cafa3/'\n",
    "        self.resume = '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_postmlp_fv_bpo__new_adj_top2down_t4f8/checkpoint_10.pth'\n",
    "        self.batch_size = 4\n",
    "        self.workers=1\n",
    "        self.namespace = 'bpo'\n",
    "        self.temperature=4\n",
    "        self.components_factor=8\n",
    "\n",
    "# Dataset and DataLoader\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepfold.utils.make_graph import build_graph\n",
    "from deepfold.utils.model import load_model_checkpoint\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from typing import Dict\n",
    "import esm\n",
    "import gc\n",
    "import random\n",
    "\n",
    "class TestAttentionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 test_file_name,\n",
    "                 label_map,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 max_length: int = 1024,\n",
    "                 truncate: bool = True,\n",
    "                 random_crop: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seqs, self.res = self.load_dataset(test_file_name)\n",
    "        self.terms_dict = label_map\n",
    "        self.num_classes = len(self.terms_dict)\n",
    "        self.max_length = max_length\n",
    "        self.truncate = truncate\n",
    "        self.random_crop = random_crop\n",
    "\n",
    "        esm_model, self.alphabet = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.free_memory(esm_model)\n",
    "    \n",
    "    def free_memory(self, esm_model):\n",
    "        del esm_model\n",
    "        gc.collect()\n",
    "        print('Delete the esm model, free memory!')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.seqs[idx]\n",
    "        if self.truncate:\n",
    "            sequence = sequence[:self.max_length - 2]\n",
    "        length = len(sequence)\n",
    "        multilabel = [0] * self.num_classes\n",
    "        return sequence, length, multilabel,self.res[idx]\n",
    "\n",
    "    def load_dataset(self, test_df_file):\n",
    "        df = pd.read_pickle(test_df_file)\n",
    "        seq = list(df['sequence'])\n",
    "        res = list(df['res'])\n",
    "        return seq,res\n",
    "\n",
    "    def collate_fn(self, examples) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Function to transform tokens string to IDs; it depends on the model\n",
    "        used.\"\"\"\n",
    "        sequences_list = [ex[0] for ex in examples]\n",
    "        lengths = [ex[1] for ex in examples]\n",
    "        multilabel_list = [ex[2] for ex in examples]\n",
    "        res_list = [ex[3] for ex in examples]\n",
    "\n",
    "        labels, strs, all_tokens = self.batch_converter([\n",
    "            ('', sequence) for sequence in sequences_list\n",
    "        ])\n",
    "\n",
    "        # The model is trained on truncated sequences and passing longer ones in at\n",
    "        # infernce will cause an error. See https://github.com/facebookresearch/esm/issues/21\n",
    "        if self.truncate:\n",
    "            all_tokens = all_tokens[:, :self.max_length]\n",
    "\n",
    "        if all_tokens.shape[1] < 1024:\n",
    "            tmp = torch.ones((all_tokens.shape[0], 1024 - all_tokens.shape[1]))\n",
    "            all_tokens = torch.cat([all_tokens, tmp], dim=1)\n",
    "        all_tokens = all_tokens.int()\n",
    "        all_tokens = all_tokens.to('cpu')\n",
    "        encoded_inputs = {\n",
    "            'input_ids': all_tokens,\n",
    "        }\n",
    "        encoded_inputs['lengths'] = torch.tensor(lengths, dtype=torch.int)\n",
    "        encoded_inputs['labels'] = torch.tensor(multilabel_list,\n",
    "                                                dtype=torch.int)\n",
    "        encoded_inputs['res'] = res_list\n",
    "        return encoded_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated terms: 19901\n",
      "number of edges:38021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete the esm model, free memory!\n"
     ]
    }
   ],
   "source": [
    "args.gpu = 0\n",
    "# Dataset and DataLoader\n",
    "adj, multi_hot_vector, label_map, label_map_ivs,_ = build_graph(\n",
    "    data_path=args.data_path, namespace=args.namespace)\n",
    "test_dataset = TestAttentionDataset(test_file_name='test_res.pkl',label_map=label_map)\n",
    "# dataloders\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=args.workers,\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_postmlp_fv_bpo__new_adj_top2down_t4f8/checkpoint_10.pth'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# model\n",
    "terms_all = pd.read_pickle(os.path.join(args.data_path,'all_terms_partial_order_embeddings.pkl'))\n",
    "terms = pd.read_pickle(os.path.join(args.data_path,args.namespace,args.namespace + '_terms.pkl'))\n",
    "terms_embedding = terms.merge(terms_all)\n",
    "embeddings = np.concatenate([np.array(embedding,ndmin=2) for embedding in terms_embedding.embeddings.values])\n",
    "terms_embedding = torch.Tensor(embeddings)\n",
    "terms_embedding = terms_embedding.cuda()\n",
    "adj = adj.cuda()\n",
    "model = P2GO(terms_embedding, adj, model_dir= 'esm1b_t33_650M_UR50S', aa_dim= 1280, latent_dim = 256, dropout_rate=0.1,temperature=args.temperature,components_factor=args.components_factor)\n",
    "\n",
    "if args.resume is not None:\n",
    "    model_state, optimizer_state = load_model_checkpoint(args.resume)\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005874340211484921\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "score_total = []\n",
    "for i,batch in enumerate(test_loader):\n",
    "    lengths = batch['lengths']\n",
    "    ress = batch['res']\n",
    "    batch = {key: val.cuda() for key, val in batch.items() if type(val) is torch.Tensor}\n",
    "    (_, logits, weights) = model(**batch)\n",
    "    preds = logits.sigmoid().detach().cpu()\n",
    "    weights = weights.detach().cpu()\n",
    "    for pred,weight,length,res in zip(preds,weights,lengths,ress):\n",
    "        idxs = pred.sort(descending=True).indices[pred.sort(descending=True).values>0.40]\n",
    "        score_sample =[]\n",
    "        for idx in idxs:\n",
    "            sorted_weight = weight[idx].sort(descending=True)\n",
    "            candidate = sorted_weight.indices[sorted_weight.values > 4/length]-1\n",
    "            candidate = candidate.detach().cpu().numpy()\n",
    "            score = len(set(list(candidate)).intersection(set(res)))/len(set(list(candidate)).union(set(res)))\n",
    "            score_sample.append(score)\n",
    "        score_total.append(sum(score_sample)/len(score_sample))\n",
    "print(sum(score_total)/len(score_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test p2go partial component postmlp t2f4 cco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated terms: 2470\n",
      "number of edges:3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete the esm model, free memory!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/niejianzheng/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_cco__new_adj_top2down_t2f4/checkpoint_8.pth'\n",
      "0.005390249583437039\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepfold.utils.make_graph import build_graph\n",
    "from deepfold.utils.model import load_model_checkpoint\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from deepfold.models.esm_model import MLPLayer,MLPLayer3D\n",
    "from deepfold.models.gnn_model import GCN\n",
    "\n",
    "# attention  module\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项 Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作.\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力.\"\"\"\n",
    "    def __init__(self, dropout, lambd=1,**kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.lambd = lambd\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(self.lambd * d)\n",
    "        # scores /= self.tao\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values),self.attention_weights\n",
    "\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状.\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作.\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力.\"\"\"\n",
    "    def __init__(self,\n",
    "                 key_size,\n",
    "                 query_size,\n",
    "                 value_size,\n",
    "                 num_hiddens,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 bias=False,\n",
    "                 lambd=None,\n",
    "                 **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout,lambd=lambd)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None, output_attentions=True):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(valid_lens,\n",
    "                                                 repeats=self.num_heads,\n",
    "                                                 dim=0)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output,weight = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        weight_concat = transpose_output(weight, self.num_heads)\n",
    "        outputs = (output_concat, weight_concat) if output_attentions else (output_concat,)\n",
    "        return outputs\n",
    "\n",
    "class LabelBasedAttention(nn.Module):\n",
    "    def __init__(self, label_dim, word_dim, latent_dim, nb_labels, nb_words,components_factor=2,temperature=2):\n",
    "        super().__init__()\n",
    "        self.label_dim = label_dim\n",
    "        self.word_dim = word_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc_label = MLPLayer(self.label_dim, self.latent_dim)\n",
    "        self.fc_word = MLPLayer3D(self.word_dim, self.latent_dim)\n",
    "        self.nb_labels = nb_labels\n",
    "        self.nb_words = nb_words\n",
    "        assert components_factor > 0\n",
    "        self.nb_components = int(self.nb_labels/(components_factor*(1+int(self.nb_labels/self.nb_words))))\n",
    "        self.component_embedding = nn.Parameter(torch.randn((self.nb_components,self.latent_dim)),requires_grad=True)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, label_embedding, word_embedding, lengths):\n",
    "        word_embedding = self.fc_word(word_embedding)\n",
    "        label_embedding = self.fc_label(label_embedding)\n",
    "        word_embedding = word_embedding.transpose(-1,-2)\n",
    "        component_embedding = self.component_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        c_w = torch.bmm(component_embedding,word_embedding)\n",
    "        label_embedding = label_embedding.repeat((word_embedding.shape[0], 1, 1))\n",
    "        l_c = torch.bmm(label_embedding,component_embedding.transpose(-1,-2))\n",
    "        l_c = l_c.softmax(dim=-1)\n",
    "        l_w = torch.bmm(l_c,c_w)\n",
    "        l_w /= self.temperature\n",
    "        l_w = masked_softmax(l_w, lengths+1)\n",
    "        label_level_embedding = torch.bmm(l_w,word_embedding.transpose(-1,-2))\n",
    "        \n",
    "        return label_level_embedding, l_w\n",
    "\n",
    "class P2GO(nn.Module):\n",
    "    def __init__(self,\n",
    "                 terms_embedding,adj,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 aa_dim=1280,\n",
    "                 latent_dim=256,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.terms_embedding = nn.Parameter(terms_embedding,requires_grad=True)\n",
    "        self.terms_dim = terms_embedding.shape[1]\n",
    "        self.latent_dim = latent_dim\n",
    "        self.adj = adj\n",
    "        \n",
    "        # backbone\n",
    "        backbone, _ = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        unfreeze_layers = None # [32] # total 0-32 layer\n",
    "        self.backbone = self.unfreeze(backbone,unfreeze_layers)\n",
    "        self.nb_classes = adj.shape[0]\n",
    "        # label based attention\n",
    "        self.label_attention = LabelBasedAttention(label_dim=self.terms_dim,word_dim=aa_dim,latent_dim=latent_dim,nb_labels=self.nb_classes,nb_words=1024,\n",
    "                                                    components_factor=4,temperature=2)\n",
    "        # go transform\n",
    "        self.go_transfrom = MLPLayer(self.terms_dim,self.latent_dim)\n",
    "        # gnn module\n",
    "        self.gcn = GCN(latent_dim, latent_dim)\n",
    "        # output layer\n",
    "        self.go_transform_post = MLPLayer(int(2 * latent_dim), latent_dim)\n",
    "        # post mlp\n",
    "        self.post_mlp = MLPLayer(self.nb_classes, self.nb_classes)\n",
    "\n",
    "    def unfreeze(self, backbone, unfreeze_layers:list):\n",
    "        for name ,param in backbone.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        if unfreeze_layers is not None:\n",
    "            if 'lm_head' in name:\n",
    "                param.requires_grad = True\n",
    "            for idx in unfreeze_layers:\n",
    "                for _, p in backbone.layers[idx].named_parameters():\n",
    "                    p.requires_grad = True\n",
    "        return backbone\n",
    "\n",
    "    def forward(self, input_ids, lengths, labels, output_attention_weights=True):\n",
    "        # backbone\n",
    "        x = self.backbone(input_ids, repr_layers=[33])['representations'][33]\n",
    "        # x = x[:, 1:]\n",
    "        # x [B,L,C]\n",
    "        label_level_embedding, weights = self.label_attention(self.terms_embedding, x, lengths)\n",
    "        go_embedding = self.go_transfrom(self.terms_embedding)\n",
    "        # go embedding\n",
    "        go_out = self.gcn(go_embedding, self.adj)\n",
    "        # output layer\n",
    "        go_out = torch.cat((go_embedding, go_out), dim=1)\n",
    "        go_out = self.go_transform_post(go_out)\n",
    "        go_out = go_out.repeat((x.shape[0], 1, 1))\n",
    "        logits = self.post_mlp(torch.sum(go_out * label_level_embedding, dim=-1))\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(logits.view(-1, self.nb_classes),\n",
    "                            labels.view(-1, self.nb_classes))\n",
    "            outputs = (logits,loss)\n",
    "        if output_attention_weights:\n",
    "            outputs = (loss, logits, weights)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class Args:\n",
    "    def __init__(self) -> None:\n",
    "        self.data_path='esm'\n",
    "        self.data_path='/share/home/niejianzheng/xbiome/datasets/protein/cafa3/'\n",
    "        self.resume = '/home/wangbin/X-DeepGO/work_dir/p2go_partial_component_cco__new_adj_top2down_t2f4/checkpoint_8.pth'\n",
    "        self.batch_size = 4\n",
    "        self.workers=1\n",
    "        self.namespace = 'cco'\n",
    "\n",
    "# Dataset and DataLoader\n",
    "args = Args()\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from typing import Dict\n",
    "import esm\n",
    "import gc\n",
    "import random\n",
    "\n",
    "class TestAttentionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 test_file_name,\n",
    "                 label_map,\n",
    "                 model_dir: str = 'esm1b_t33_650M_UR50S',\n",
    "                 max_length: int = 1024,\n",
    "                 truncate: bool = True,\n",
    "                 random_crop: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seqs, self.res = self.load_dataset(test_file_name)\n",
    "        self.terms_dict = label_map\n",
    "        self.num_classes = len(self.terms_dict)\n",
    "        self.max_length = max_length\n",
    "        self.truncate = truncate\n",
    "        self.random_crop = random_crop\n",
    "\n",
    "        esm_model, self.alphabet = esm.pretrained.load_model_and_alphabet(\n",
    "            model_dir)\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.free_memory(esm_model)\n",
    "    \n",
    "    def free_memory(self, esm_model):\n",
    "        del esm_model\n",
    "        gc.collect()\n",
    "        print('Delete the esm model, free memory!')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.seqs[idx]\n",
    "        if self.truncate:\n",
    "            sequence = sequence[:self.max_length - 2]\n",
    "        length = len(sequence)\n",
    "        multilabel = [0] * self.num_classes\n",
    "        return sequence, length, multilabel,self.res[idx]\n",
    "\n",
    "    def load_dataset(self, test_df_file):\n",
    "        df = pd.read_pickle(test_df_file)\n",
    "        seq = list(df['sequence'])\n",
    "        res = list(df['res'])\n",
    "        return seq,res\n",
    "\n",
    "    def collate_fn(self, examples) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Function to transform tokens string to IDs; it depends on the model\n",
    "        used.\"\"\"\n",
    "        sequences_list = [ex[0] for ex in examples]\n",
    "        lengths = [ex[1] for ex in examples]\n",
    "        multilabel_list = [ex[2] for ex in examples]\n",
    "        res_list = [ex[3] for ex in examples]\n",
    "\n",
    "        labels, strs, all_tokens = self.batch_converter([\n",
    "            ('', sequence) for sequence in sequences_list\n",
    "        ])\n",
    "\n",
    "        # The model is trained on truncated sequences and passing longer ones in at\n",
    "        # infernce will cause an error. See https://github.com/facebookresearch/esm/issues/21\n",
    "        if self.truncate:\n",
    "            all_tokens = all_tokens[:, :self.max_length]\n",
    "\n",
    "        if all_tokens.shape[1] < 1024:\n",
    "            tmp = torch.ones((all_tokens.shape[0], 1024 - all_tokens.shape[1]))\n",
    "            all_tokens = torch.cat([all_tokens, tmp], dim=1)\n",
    "        all_tokens = all_tokens.int()\n",
    "        all_tokens = all_tokens.to('cpu')\n",
    "        encoded_inputs = {\n",
    "            'input_ids': all_tokens,\n",
    "        }\n",
    "        encoded_inputs['lengths'] = torch.tensor(lengths, dtype=torch.int)\n",
    "        encoded_inputs['labels'] = torch.tensor(multilabel_list,\n",
    "                                                dtype=torch.int)\n",
    "        encoded_inputs['res'] = res_list\n",
    "        return encoded_inputs\n",
    "\n",
    "args.gpu = 0\n",
    "# Dataset and DataLoader\n",
    "adj, multi_hot_vector, label_map, label_map_ivs,_ = build_graph(\n",
    "    data_path=args.data_path, namespace=args.namespace)\n",
    "test_dataset = TestAttentionDataset(test_file_name='test_res.pkl',label_map=label_map)\n",
    "# dataloders\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=args.workers,\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=test_dataset.collate_fn)\n",
    "import numpy as np\n",
    "# model\n",
    "terms_all = pd.read_pickle(os.path.join(args.data_path,'all_terms_partial_order_embeddings.pkl'))\n",
    "terms = pd.read_pickle(os.path.join(args.data_path,args.namespace,args.namespace + '_terms.pkl'))\n",
    "terms_embedding = terms.merge(terms_all)\n",
    "embeddings = np.concatenate([np.array(embedding,ndmin=2) for embedding in terms_embedding.embeddings.values])\n",
    "terms_embedding = torch.Tensor(embeddings)\n",
    "terms_embedding = terms_embedding.cuda()\n",
    "adj = adj.cuda()\n",
    "model = P2GO(terms_embedding, adj, model_dir= 'esm1b_t33_650M_UR50S', aa_dim= 1280, latent_dim = 256, dropout_rate=0.1)\n",
    "if args.resume is not None:\n",
    "    model_state, optimizer_state = load_model_checkpoint(args.resume)\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "score_total = []\n",
    "for i,batch in enumerate(test_loader):\n",
    "    lengths = batch['lengths']\n",
    "    ress = batch['res']\n",
    "    batch = {key: val.cuda() for key, val in batch.items() if type(val) is torch.Tensor}\n",
    "    (_, logits, weights) = model(**batch)\n",
    "    preds = logits.sigmoid().detach().cpu()\n",
    "    weights = weights.detach().cpu()\n",
    "    for pred,weight,length,res in zip(preds,weights,lengths,ress):\n",
    "        idxs = pred.sort(descending=True).indices[pred.sort(descending=True).values>0.5]\n",
    "        \n",
    "        score_sample =[]\n",
    "        for idx in idxs:\n",
    "            sorted_weight = weight[idx].sort(descending=True)\n",
    "            candidate = sorted_weight.indices[sorted_weight.values > 4/length]-1\n",
    "            candidate = candidate.detach().cpu().numpy()\n",
    "            score = len(set(list(candidate)).intersection(set(res)))/len(set(list(candidate)).union(set(res)))\n",
    "            score_sample.append(score)\n",
    "        score_total.append(sum(score_sample)/len(score_sample))\n",
    "print(sum(score_total)/len(score_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "944e460067bd0e7eb2da401531251355f13e791f93719a62bf1e1da598329366"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
